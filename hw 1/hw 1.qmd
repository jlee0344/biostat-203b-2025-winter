---
title: "Biostat 203B Homework 1"
subtitle: Due Jan 24, 2025 @ 11:59PM
author: Julie Lee, 806409381 
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
    link-external-icon: true
    link-external-newwindow: true
editor: 
  markdown: 
    wrap: sentence
---

Display machine information for reproducibility:

```{r}
#| eval: true
sessionInfo()
```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We work with Git and GitHub.
Efficient and abundant use of Git, e.g., frequent and well-documented commits, is an important criterion for grading your homework.

1.  Apply for the [Student Developer Pack](https://education.github.com/pack) at GitHub using your UCLA email.
    You'll get GitHub Pro account for free (unlimited public and private repositories).
    **Completed.**

2.  Create a **private** repository `biostat-203b-2025-winter` and add `Hua-Zhou` and TA team (`Tomoki-Okuno` for Lec 1; `parsajamshidian` and `BowenZhang2001` for Lec 82) as your collaborators with write permission.
    **Completed.**

3.  Top directories of the repository should be `hw1`, `hw2`, ...
    Maintain two branches `main` and `develop`.
    The `develop` branch will be your main playground, the place where you develop solution (code) to homework problems and write up report.
    The `main` branch will be your presentation area.
    Submit your homework files (Quarto file `qmd`, `html` file converted by Quarto, all code and extra data sets to reproduce results) in the `main` branch.
    **Completed.**

4.  After each homework due date, course reader and instructor will check out your `main` branch for grading.
    Tag each of your homework submissions with tag names `hw1`, `hw2`, ...
    Tagging time will be used as your submission time.
    That means if you tag your `hw1` submission after deadline, penalty points will be deducted for late submission.
    **Completed.**

5.  After this course, you can make this repository public and use it to demonstrate your skill sets on job market.

## Q2. Data ethics training

This exercise (and later in this course) uses the [MIMIC-IV data v3.1](https://physionet.org/content/mimiciv/3.1/), a freely accessible critical care database developed by the MIT Lab for Computational Physiology.
Follow the instructions at <https://mimic.mit.edu/docs/gettingstarted/> to (1) complete the CITI `Data or Specimens Only Research` course and (2) obtain the PhysioNet credential for using the MIMIC-IV data.
Display the verification links to your completion report and completion certificate here.
**You must complete Q2 before working on the remaining questions.** (Hint: The CITI training takes a few hours and the PhysioNet credentialing takes a couple days; do not leave it to the last minute.)

**Solution:** Here is the [Completion Report](https://www.citiprogram.org/verify/?ka99bf20e-e7bc-45a1-bdb0-d1f88046b522-67197093) of my CITI Training.

Here is the [Completion Certification](https://www.citiprogram.org/verify/?w58649c8c-434a-4577-b55b-295333b28932-67197093) of my CITI Training.

## Q3. Linux Shell Commands

1.  Make the MIMIC-IV v3.1 data available at location `~/mimic`. The output of the `ls -l ~/mimic` command should be similar to the below (from my laptop).

**(3.1) Solution:** I downloaded the MIMIC IV v3.1 data and it is available under \`\~/mimic' folder as requested.

```{bash}
#| eval: true
# content of mimic folder
ls -l ~/mimic/
```

Refer to the documentation <https://physionet.org/content/mimiciv/3.1/> for details of data files.
Do **not** put these data files into Git; they are big.
Do **not** copy them into your directory.
Do **not** decompress the gz data files.
These create unnecessary big files and are not big-data-friendly practices.
Read from the data folder `~/mimic` directly in following exercises.

Use Bash commands to answer following questions.

2.  Display the contents in the folders `hosp` and `icu` using Bash command `ls -l`. Why are these data files distributed as `.csv.gz` files instead of `.csv` (comma separated values) files? Read the page <https://mimic.mit.edu/docs/iv/> to understand what's in each folder.

**(3.2) Solution:** Here is the content of 'hosp' folder:

```{bash}
ls -l ~/mimic/hosp/
```

Here is the content of 'icu' folder:

```{bash}
ls -l ~/mimic/icu/
```

These data were distributed as ".csv.gz" files instead of .csv files because the ".gz" extension insinuates that the CSV data has been compressed due to its large size. When compressing the CSV file, the underlying data format is still CSV but users are more easily able to open and the read the data in any CSV reader even after decompression. The data that we downloaded (Mimic) is an extremely large file and beig able to compress it using the Gzip algorithm reduces the file size and makes it more efficient to store.

3.  Briefly describe what Bash commands `zcat`, `zless`, `zmore`, and `zgrep` do.

**(3.3) Solution:** The Bash command `zcat` is equivalent to the cat for gzip-compressed files.
It is used to output the contents of the .gz file without creating an uncompressed version of the file.

The Bash command `zless`is similar to the less command. It allows users to view the contents of the compressed files without having to decompress or extract them.

The Bash command `zmore`is used to display compressed or plan text files one screen at a time without first decompressing them.

The Bash command `zgrep`is used to search through a combination of uncompressed and compressed files without explicitly decompressing them first.

4.  (Looping in Bash) What's the output of the following bash script?

**(3.4) Solution:** The output of the following bash script is:

```{bash}
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  ls -l $datafile
done
```

Display the number of lines in each data file using a similar loop.
(Hint: combine linux commands `zcat <` and `wc -l`.)

**Solution:** The number of lines in each data file for admission.csv.gv, labevents.csv.gz, and patients.csv.gz are as follows: 

```{bash}
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  gzcat "$datafile" | wc -l
done
```

In summary, there are 546029 lines in the file 'admissions.csv.gz", there are 158374765 lines in the file 'labevents.csv.gz', and there are 364628 lines in the 'patients.csv.gz' data file. In the following code, we iterate through all the .gz files in the ~/mimic/hosp directory that matches the "a, l, pa" prefixes. The "gzcat" command decomrpepsses each file and outputs its content to standard output. Afterwards, the "wc -l" command prints the number of lines in each iterated file. 

5.  Display the first few lines of `admissions.csv.gz`. How many rows are in this data file, excluding the header line? Each `hadm_id` identifies a hospitalization. How many hospitalizations are in this data file? How many unique patients (identified by `subject_id`) are in this data file? Do they match the number of patients listed in the `patients.csv.gz` file? (Hint: combine Linux commands `zcat <`, `head`/`tail`, `awk`, `sort`, `uniq`, `wc`, and so on.)

**(3.5) Solution: ** 
The first few lines of admissions.csv.gz are:
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | head 
```

The number of rows in this data file, excluding the header line are: 
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | wc -l
```

If each hadm_id identifies a hospitalization, the number of hospitalizations in this data file is:
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | cut -d, -f2 |
sort | uniq |wc -l

```


The number of unique patients there are in this data file is: 
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | awk -F, '{print $3}' |sort |uniq | wc -l 
```


The number of patients listed in this patients.csv.gz file 
```{bash}
zcat < ~/mimic/hosp/patients.csv.gz |tail -n +2 | awk -F, '{print $1}' | sort | uniq |wc -l
```

Remark: The number of unique patients there are in the data file (identified by subject_id) does not match the number of patients listed in the patients.csv.gz file because 



6.  What are the possible values taken by each of the variable `admission_type`, `admission_location`, `insurance`, and `ethnicity`? Also report the count for each unique value of these variables in decreasing order. (Hint: combine Linux commands `zcat`, `head`/`tail`, `awk`, `uniq -c`, `wc`, `sort`, and so on; skip the header line.)

**(5.6) Solution** The possible values taken by each of the variable.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | head 

```

7. The `icusays.csv.gz` file contains all the ICU stays during the study period. How many ICU stays, identified by `stay_id`, are in this data file? How many unique patients, identified by `subject_id`, are in this data file?

**(5.7) Solution** 
There are ICU stays in this data file 



8.  *To compress, or not to compress. That's the question.* Let's focus on the big data file `labevents.csv.gz`. Compare compressed gz file size to the uncompressed file size. Compare the run times of `zcat < ~/mimic/labevents.csv.gz | wc -l` versus `wc -l labevents.csv`. Discuss the trade off between storage and speed for big data files. (Hint: `gzip -dk < FILENAME.gz > ./FILENAME`. Remember to delete the large `labevents.csv` file after the exercise.)

**(5.8) Solution:**

```{bash}

```

## Q4. Who's popular in Price and Prejudice

1.  You and your friend just have finished reading *Pride and Prejudice* by Jane Austen. Among the four main characters in the book, Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was the most mentioned. You, however, are certain it was Elizabeth. Obtain the full text of the novel from <http://www.gutenberg.org/cache/epub/42671/pg42671.txt> and save to your local folder.

```{bash}
#| eval: false
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
```

Explain what `wget -nc` does.
Do **not** put this text file `pg42671.txt` in Git.
Complete the following loop to tabulate the number of times each of the four characters is mentioned using Linux commands.

```{bash}
#| eval: false
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
for char in Elizabeth Jane Lydia Darcy
do
  echo $char:
  # some bash commands here
done
```

2.  What's the difference between the following two commands?

```{bash}
#| eval: false
echo 'hello, world' > test1.txt
```

and

```{bash}
#| eval: false
echo 'hello, world' >> test2.txt
```

3.  Using your favorite text editor (e.g., `vi`), type the following and save the file as `middle.sh`:

```{bash eval=FALSE}
#!/bin/sh
# Select lines from the middle of a file.
# Usage: bash middle.sh filename end_line num_lines
head -n "$2" "$1" | tail -n "$3"
```

Using `chmod` to make the file executable by the owner, and run

```{bash}
#| eval: false
./middle.sh pg42671.txt 20 5
```

Explain the output.
Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in this shell script.
Why do we need the first line of the shell script?

## Q5. More fun with Linux

Try following commands in Bash and interpret the results: `cal`, `cal 2025`, `cal 9 1752` (anything unusual?), `date`, `hostname`, `arch`, `uname -a`, `uptime`, `who am i`, `who`, `w`, `id`, `last | head`, `echo {con,pre}{sent,fer}{s,ed}`, `time sleep 5`, `history | tail`.

**Solution"** The "cal" command showcases the calendar for the current month.

```{bash}
cal
```

The "cal 2025" command showcases the calendar for the year 2025 (for all 12 months).

```{bash}
cal 2025 
```

The "cal 9 1752" command showcases the calendar for the month of September in the year of 1752.
However, there is unusual behavior in this command.
We are able to see that the calendar is missing 11 days (September 3 - September 13, 1752.) This is because the Gregorian calendar was adopted in 1752 and the Julian calendar was replaced.

```{bash}
cal 9 1752 
```

The "date" command showcases the current date and time in PST.

```{bash}
date 
```

The "hostname" command showcases the hostname of the current system.

```{bash}
hostname 
```

The "arch" command showcases the hardware architecture of the current system.

```{bash}
arch 
```

The "uname -a" command showcases the kernel name/version, system information, hostname, architecture, and OS of the current machine.

```{bash}
uname -a 
```

The uptime command showcases how long the machine has been running, system load averages, and the number of users logged in.

```{bash}
uptime 
```

The who am i command showcases the current user logged in (username) and login time.

```{bash}
who am i 
```

The who command showcases the list of all currently logged-in users.

```{bash}
who
```

The w command showcases information regarding the users who are currently logged into the system and their activities.
It includes system information including the current time, how long the system has been running, and the number of users logged in.
It includes user information including usernmae, terminal decive, login time, idle time, and current directory used.

```{bash}
w
```

The id command showcases the user ID, groupID, user name, and the groups for the current user.

```{bash}
id 
```

The last \| head command showcases the most recent logins (first 10 logg-in users).

```{bash}
last | head 
```

The echo {con, pre} {sent,fer}{s,ed} command showcases different combinations of words.

```{bash}
echo {con,pre}{sent,fer}{s,ed}
```

The time sleep 5 command showcases how long the operation takes to execute after the system pasues for 5 seconds.

```{bash}
time sleep 5 
```

The history \| tail command showcases the last 10 commands that were executed.

```{bash}
history | tail
```

## Q6. Book

1.  Git clone the repository <https://github.com/christophergandrud/Rep-Res-Book> for the book *Reproducible Research with R and RStudio* to your local machine.
    Do **not** put this repository within your homework repository `biostat-203b-2025-winter`.

2.  Open the project by clicking `rep-res-3rd-edition.Rproj` and compile the book by clicking `Build Book` in the `Build` panel of RStudio.
    (Hint: I was able to build `git_book` and `epub_book` directly. For `pdf_book`, I needed to add a line `\usepackage{hyperref}` to the file `Rep-Res-Book/rep-res-3rd-edition/latex/preabmle.tex`.)

The point of this exercise is (1) to obtain the book for free and (2) to see an example how a complicated project such as a book can be organized in a reproducible way.
Use `sudo apt install PKGNAME` to install required Ubuntu packages and `tlmgr install PKGNAME` to install missing TexLive packages.

For grading purpose, include a screenshot of Section 4.1.5 of the book here.
\`\`\`\`
